{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b93d3ec-b1a6-4588-af41-a89839e2502a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# <span style=\"color:#1f77b4\">**Machine Learning 02 - MLflow**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc872c7-667d-406f-a2a8-57dd9123a2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Unity Catalog configuration**</span>\n",
    "\n",
    "Set up widgets for `CATALOG`, `SCHEMA`, and `VOLUME`, resolve the active catalog, and build the `BASE` path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5909c8e-1b6c-47ba-af22-0e1f966396cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure Unity Catalog widgets and resolve the active catalog.\n",
    "\n",
    "# Unity Catalog config for this project\n",
    "dbutils.widgets.removeAll()\n",
    "dbutils.widgets.text(\"CATALOG\", \"\")\n",
    "dbutils.widgets.text(\"SCHEMA\", \"default\")\n",
    "dbutils.widgets.text(\"VOLUME\", \"ml_lab\")\n",
    "\n",
    "catalog_widget = dbutils.widgets.get(\"CATALOG\")\n",
    "if catalog_widget:\n",
    "    CATALOG = catalog_widget\n",
    "else:\n",
    "    # Prefer current catalog, otherwise pick the first non-system catalog\n",
    "    current = spark.sql(\"SELECT current_catalog()\").first()[0]\n",
    "    catalogs = [r.catalog for r in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "    CATALOG = current if current not in (\"system\",) else next(c for c in catalogs if c not in (\"system\",))\n",
    "\n",
    "SCHEMA = dbutils.widgets.get(\"SCHEMA\")\n",
    "VOLUME = dbutils.widgets.get(\"VOLUME\")\n",
    "BASE = f\"dbfs:/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9c0319-0b39-4038-a2f5-08312dafd36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Create schema and volume**</span>\n",
    "\n",
    "Ensure the Unity Catalog schema and volume exist before loading data or saving models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa3cbec6-e94d-4c19-84d5-847828524ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the schema and volume if needed.\n",
    "\n",
    "# Ensure schema and volume exist\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.{VOLUME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6a3467-36f9-4daf-a708-1f3c07425407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Load data into the UC volume**</span>\n",
    "\n",
    "Copy the diabetes CSV into the Unity Catalog volume only if it is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015c8360-2077-475e-8618-838ae2f7bfbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Avoid overwriting shared files during pipeline runs.\n",
    "\n",
    "# Sync raw data files into the UC volume (only if missing)\n",
    "data_dir = f\"{BASE}/diabetes\"\n",
    "data_file = f\"{data_dir}/diabetes.csv\"\n",
    "try:\n",
    "    dbutils.fs.ls(data_file)\n",
    "    file_exists = True\n",
    "except Exception:\n",
    "    file_exists = False\n",
    "\n",
    "if not file_exists:\n",
    "    dbutils.fs.mkdirs(data_dir)\n",
    "    dbutils.fs.cp(\"https://raw.githubusercontent.com/Ch3rry-Pi3-Azure/DataBricks-Machine-Learning/refs/heads/main/data/diabetes.csv\", data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d8f866b-fb65-4056-91b5-7386d885b814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Load, clean, and split data**</span>\n",
    "\n",
    "Read the CSV, cast columns, remove nulls, and create train/test splits for model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81a37c2-495d-432b-923f-734189b51bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 523  Testing Rows: 245\n"
     ]
    }
   ],
   "source": [
    "# Cast columns and split into train/test sets.\n",
    "\n",
    "# Import required libraries\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "   \n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(BASE + \"/diabetes/diabetes.csv\")\n",
    "data = data.dropna().select(col(\"Pregnancies\").astype(\"int\"),\n",
    "                           col(\"Glucose\").astype(\"int\"),\n",
    "                          col(\"BloodPressure\").astype(\"int\"),\n",
    "                          col(\"SkinThickness\").astype(\"int\"),\n",
    "                          col(\"Insulin\").astype(\"int\"),\n",
    "                          col(\"BMI\").astype(\"float\"),\n",
    "                          col(\"DiabetesPedigreeFunction\").astype(\"float\"),\n",
    "                          col(\"Age\").astype(\"int\"),\n",
    "                          col(\"Outcome\").astype(\"int\")\n",
    "                          )\n",
    "\n",
    "   \n",
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c04629-6307-47ef-9eb0-db80fb512bc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Define the MLflow training function**</span>\n",
    "\n",
    "Use MLflow to track parameters and metrics while training a Spark ML pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c3d0275-08cb-4e79-a225-8d6b87f0b7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build a pipeline, log metrics with MLflow, and save the model.\n",
    "\n",
    "def train_diabetes_model(training_data, test_data, maxIterations, regularization):\n",
    "    import mlflow\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    import time\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        numFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "        numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "        numScaler = MinMaxScaler(inputCol=numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "        featureVector = VectorAssembler(inputCols=[\"normalizedFeatures\"], outputCol=\"features\")\n",
    "        algo = LogisticRegression(labelCol=\"Outcome\", featuresCol=\"features\", maxIter=maxIterations, regParam=regularization)\n",
    "        pipeline = Pipeline(stages=[numVector, numScaler, featureVector, algo])\n",
    "        \n",
    "        mlflow.log_param('maxIter', algo.getMaxIter())\n",
    "        mlflow.log_param('regParam', algo.getRegParam())\n",
    "        model = pipeline.fit(training_data)\n",
    "        \n",
    "        prediction = model.transform(test_data)\n",
    "        metrics = [\"accuracy\", \"weightedRecall\", \"weightedPrecision\"]\n",
    "        for metric in metrics:\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=metric)\n",
    "            metricValue = evaluator.evaluate(prediction)\n",
    "            print(f\"{metric}: {metricValue}\")\n",
    "            mlflow.log_metric(metric, metricValue)\n",
    "        \n",
    "        unique_model_name = \"classifier-\" + str(time.time())\n",
    "        model_path = BASE + f\"/models/{unique_model_name}\"\n",
    "        model.write().overwrite().save(model_path)\n",
    "        print(\"Experiment run complete. Model saved to\", model_path)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1070353-5c9b-41ff-81a7-8c2f923a9efc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Run experiment: config A**</span>\n",
    "\n",
    "Train and log a model run with a smaller iteration count and higher regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ee408b3-b5bc-4e54-aab7-d2b2b3ba439a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7020408163265306\nweightedRecall: 0.7020408163265306\nweightedPrecision: 0.7627482993197279\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/28 21:24:53 INFO mlflow.tracking._tracking_service.client: \uD83C\uDFC3 View run dazzling-mole-391 at: adb-7405608564792326.6.azuredatabricks.net/ml/experiments/2636880519013446/runs/eee233e8296d444fa5e80ab75493b707.\n2025/12/28 21:24:53 INFO mlflow.tracking._tracking_service.client: \uD83E\uDDEA View experiment at: adb-7405608564792326.6.azuredatabricks.net/ml/experiments/2636880519013446.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run complete. Model saved to dbfs:/Volumes/dbw_databricks_ml_jaguar/default/ml_lab/models/classifier-1766957085.9095488\n"
     ]
    }
   ],
   "source": [
    "# First experiment run with chosen hyperparameters.\n",
    "\n",
    "modeb_a = train_diabetes_model(train, test, 5, 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf7dd14-0977-4765-b4dc-776047e3fda0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Run experiment: config B**</span>\n",
    "\n",
    "Train and log a model run with more iterations and lower regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e5068bb-418e-4320-a5c2-bab375ffcccf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7591836734693878\nweightedRecall: 0.7591836734693878\nweightedPrecision: 0.7702799647777893\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/28 21:25:08 INFO mlflow.tracking._tracking_service.client: \uD83C\uDFC3 View run redolent-rook-161 at: adb-7405608564792326.6.azuredatabricks.net/ml/experiments/2636880519013446/runs/f00c1519aaf2471ab0e667a4dd474a43.\n2025/12/28 21:25:08 INFO mlflow.tracking._tracking_service.client: \uD83E\uDDEA View experiment at: adb-7405608564792326.6.azuredatabricks.net/ml/experiments/2636880519013446.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment run complete. Model saved to dbfs:/Volumes/dbw_databricks_ml_jaguar/default/ml_lab/models/classifier-1766957101.2997136\n"
     ]
    }
   ],
   "source": [
    "# Second experiment run for comparison.\n",
    "\n",
    "model_b = train_diabetes_model(train, test, 10, 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d45fc3b8-6f2e-43bc-a810-b74baebe2136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Save and register the model in Unity Catalog**</span>\n",
    "\n",
    "Persist an MLflow model artifact to the Unity Catalog volume and register it so it appears in the Models tab. This creates a new version each time you run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48570dfc-aa30-4dcf-9d36-fcf8cb596c64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n2025/12/28 21:25:27 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7b7dc8e1da4ceda4f10eb0e7e03502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/28 21:26:02 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/2636880519013446/f0d54207f3fa4dbbb09c76e022a0ef9b/artifacts/model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.2']. Set logging level to DEBUG to see the full traceback. \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15912273be1b4b748a6afa091b2ae384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'dbw_databricks_ml_jaguar.default.diabetes_lr' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54083c64605e4a84ab9761067a8959b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d5cddbf5784269b5c2f8f41f27da60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'dbw_databricks_ml_jaguar.default.diabetes_lr'.\n2025/12/28 21:26:09 INFO mlflow.tracking._tracking_service.client: \uD83C\uDFC3 View run bouncy-slug-708 at: adb-7405608564792326.6.azuredatabricks.net/ml/experiments/2636880519013446/runs/f0d54207f3fa4dbbb09c76e022a0ef9b.\n2025/12/28 21:26:09 INFO mlflow.tracking._tracking_service.client: \uD83E\uDDEA View experiment at: adb-7405608564792326.6.azuredatabricks.net/ml/experiments/2636880519013446.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered dbw_databricks_ml_jaguar.default.diabetes_lr from run f0d54207f3fa4dbbb09c76e022a0ef9b\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Use Unity Catalog volume for MLflow temp staging and artifacts\n",
    "mlflow_tmp = f\"{BASE}/mlflow_tmp\"\n",
    "dbutils.fs.mkdirs(mlflow_tmp)\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = mlflow_tmp\n",
    "\n",
    "# Choose which trained model to register\n",
    "model = model_b\n",
    "\n",
    "# Build input/output samples to infer model signature\n",
    "feature_cols = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "input_df = train.select(*feature_cols).limit(20)\n",
    "output_df = model.transform(input_df).select(\"prediction\").limit(20)\n",
    "signature = infer_signature(input_df, output_df)\n",
    "input_example = input_df.limit(5).toPandas()\n",
    "\n",
    "# Register the model in Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = f\"{CATALOG}.{SCHEMA}.diabetes_lr\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    print(f\"Registered {model_name} from run {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70767745-22f1-48d1-9697-436f1e194ed1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Sample request payload**</span>\n",
    "\n",
    "Example JSON payload for real?time model scoring endpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f83a032-5bd9-4971-8dc1-5c4e21d3086e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dataframe_records': [{'Pregnancies': 8,\n",
       "   'Glucose': 85,\n",
       "   'BloodPressure': 65,\n",
       "   'SkinThickness': 29,\n",
       "   'Insulin': 0,\n",
       "   'BMI': 26.6,\n",
       "   'DiabetesPedigreeFunction': 0.672,\n",
       "   'Age': 34}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "   \"dataframe_records\": [\n",
    "   {\n",
    "      \"Pregnancies\": 8,\n",
    "      \"Glucose\": 85,\n",
    "      \"BloodPressure\": 65,\n",
    "      \"SkinThickness\": 29,\n",
    "      \"Insulin\": 0,\n",
    "      \"BMI\": 26.6,\n",
    "      \"DiabetesPedigreeFunction\": 0.672,\n",
    "      \"Age\": 34\n",
    "   }\n",
    "   ]\n",
    " }\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_mlflow.ipynb",
   "widgets": {
    "CATALOG": {
     "currentValue": "",
     "nuid": "ddf0e8b1-b391-49f0-b438-3040dbab30d9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "CATALOG",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "CATALOG",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "SCHEMA": {
     "currentValue": "default",
     "nuid": "7f5fda86-292d-44a1-ac34-f86691e4ff77",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": null,
      "name": "SCHEMA",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default",
      "label": null,
      "name": "SCHEMA",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "VOLUME": {
     "currentValue": "ml_lab",
     "nuid": "3d5ee89b-7506-44b2-a805-354cf5559da4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ml_lab",
      "label": null,
      "name": "VOLUME",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ml_lab",
      "label": null,
      "name": "VOLUME",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}